{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "EoCM85d84gVS"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "texts = [\"I love programming\",\n",
        "         \"Python is awesome\",\n",
        "         \"I hate bugs\",\n",
        "         \"Debugging is fun\",\n",
        "         \"I love solving problems\",\n",
        "         \"I don't like errors\"]\n",
        "labels = [1, 1, 0, 1, 1, 0]\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n"
      ],
      "metadata": {
        "id": "T6oH0FxF4-A2"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ug9RCY2-Ul-H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(texts)\n",
        "\n"
      ],
      "metadata": {
        "id": "BG4GPbbZ5ZdN"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequences = tokenizer.texts_to_sequences(texts)\n",
        "sequences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-JoY9iSU5xLk",
        "outputId": "0aabecf9-16b0-4d3e-fbcf-c879b543f5e4"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[1, 2, 4], [5, 3, 6], [1, 7, 8], [9, 3, 10], [1, 2, 11, 12], [1, 13, 14, 15]]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_length = max([len(sequence)\n",
        " for sequence in sequences])\n",
        "max_length"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LtwUnDq-53iY",
        "outputId": "d6cf9da1-87d6-4807-e810-3eae981d1931"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = pad_sequences(sequences, maxlen=max_length,\n",
        "                  padding='post')\n",
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OJhrFCa76DXb",
        "outputId": "bffe5858-8f7f-4f12-f0b2-cae93e4f58e6"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1,  2,  4,  0],\n",
              "       [ 5,  3,  6,  0],\n",
              "       [ 1,  7,  8,  0],\n",
              "       [ 9,  3, 10,  0],\n",
              "       [ 1,  2, 11, 12],\n",
              "       [ 1, 13, 14, 15]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = np.array(labels)\n",
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3QE2EyFI6Ot7",
        "outputId": "670a0d4d-bd5a-4920-c706-c6013aa99f4c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 0, 1, 1, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers  import Embedding, Dense, Flatten\n"
      ],
      "metadata": {
        "id": "M6uAGYUD6had"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.word_index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Is4bDhy669ia",
        "outputId": "4e68c989-827f-4a72-cbb5-92e16a2f8644"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'i': 1,\n",
              " 'love': 2,\n",
              " 'is': 3,\n",
              " 'programming': 4,\n",
              " 'python': 5,\n",
              " 'awesome': 6,\n",
              " 'hate': 7,\n",
              " 'bugs': 8,\n",
              " 'debugging': 9,\n",
              " 'fun': 10,\n",
              " 'solving': 11,\n",
              " 'problems': 12,\n",
              " \"don't\": 13,\n",
              " 'like': 14,\n",
              " 'errors': 15}"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=len(tokenizer.word_index) + 1,\n",
        "                    output_dim=8,\n",
        "                    input_length=max_length))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(10, activation='relu'))\n",
        "\n",
        "model.add(Dense(1, activation='sigmoid'))\n"
      ],
      "metadata": {
        "id": "J_EQjGNg7E5K"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "LyFs6kkF7szG"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X, y,epochs=20, batch_size=2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G3zM_Kxj7s43",
        "outputId": "e898c437-cebb-46ad-8329-47bcf8d30ec4"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.4375 - loss: 0.6938\n",
            "Epoch 2/20\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7708 - loss: 0.6869 \n",
            "Epoch 3/20\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9167 - loss: 0.6818\n",
            "Epoch 4/20\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8542 - loss: 0.6784\n",
            "Epoch 5/20\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8542 - loss: 0.6736\n",
            "Epoch 6/20\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8542 - loss: 0.6748\n",
            "Epoch 7/20\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7292 - loss: 0.6710\n",
            "Epoch 8/20\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9167 - loss: 0.6596\n",
            "Epoch 9/20\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7292 - loss: 0.6684\n",
            "Epoch 10/20\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9167 - loss: 0.6497\n",
            "Epoch 11/20\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9167 - loss: 0.6475\n",
            "Epoch 12/20\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9167 - loss: 0.6455\n",
            "Epoch 13/20\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8542 - loss: 0.6444\n",
            "Epoch 14/20\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9167 - loss: 0.6386\n",
            "Epoch 15/20\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7292 - loss: 0.6465\n",
            "Epoch 16/20\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9167 - loss: 0.6258\n",
            "Epoch 17/20\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7292 - loss: 0.6367\n",
            "Epoch 18/20\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7292 - loss: 0.6371\n",
            "Epoch 19/20\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8542 - loss: 0.6172\n",
            "Epoch 20/20\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9167 - loss: 0.6074\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x780aad620050>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_text = \"i love programming\"\n",
        "sample_sequence = tokenizer.texts_to_sequences ([sample_text])  # Tokenize the sample text\n",
        "sample_padded = pad_sequences(sample_sequence, maxlen=max_length, padding='post')  # Pad the sequence\n",
        "prediction = model.predict(sample_padded)\n",
        "if prediction > 0.5:\n",
        "  print('positive')\n",
        "else:\n",
        "  print('negative')\n",
        "\n",
        "\n",
        "print(prediction[0][0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nFwhBvTO8EE5",
        "outputId": "f1458ba7-defd-4b95-de47-bf36265cf40a"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step\n",
            "positive\n",
            "0.5627484\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Dropout\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=8, input_length=max_length))\n",
        "model.add(Dropout(0.5))  # Dropout layer to prevent overfitting\n",
        "model.add(Flatten())\n",
        "model.add(Dense(10, activation='relu'))\n",
        "model.add(Dense(5, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X, y, epochs=20, batch_size=2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FGzvY0-48EGb",
        "outputId": "6dcb8a5a-2e15-45df-a92f-15cc2d3792f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.2623 - loss: 0.7010    \n",
            "Epoch 2/20\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5642 - loss: 0.6928 \n",
            "Epoch 3/20\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5267 - loss: 0.6911     \n",
            "Epoch 4/20\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7243 - loss: 0.6879 \n",
            "Epoch 5/20\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6399 - loss: 0.6870 \n",
            "Epoch 6/20\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5409 - loss: 0.6893     \n",
            "Epoch 7/20\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7260 - loss: 0.6828 \n",
            "Epoch 8/20\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8634 - loss: 0.6784 \n",
            "Epoch 9/20\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8852 - loss: 0.6574 \n",
            "Epoch 10/20\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8742 - loss: 0.6380 \n",
            "Epoch 11/20\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9157 - loss: 0.6180 \n",
            "Epoch 12/20\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9122 - loss: 0.5906 \n",
            "Epoch 13/20\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9750 - loss: 0.5582 \n",
            "Epoch 14/20\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8770 - loss: 0.5458 \n",
            "Epoch 15/20\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9708 - loss: 0.4842 \n",
            "Epoch 16/20\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.4289 \n",
            "Epoch 17/20\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9495 - loss: 0.3805 \n",
            "Epoch 18/20\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9750 - loss: 0.3077 \n",
            "Epoch 19/20\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.2854 \n",
            "Epoch 20/20\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.2409 \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7facf20d1e90>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_text = \"the code is very easy\"\n",
        "sample_sequence = tokenizer.texts_to_sequences([sample_text])  # Tokenize the sample text\n",
        "sample_padded = pad_sequences(sample_sequence, maxlen=max_length, padding='post')  # Pad the sequence\n",
        "prediction = model.predict(sample_padded)\n",
        "if prediction > 0.5:\n",
        "  print('positive')\n",
        "else:\n",
        "  print('negative')\n",
        "\n",
        "\n",
        "print(prediction[0][0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_9ph-B9J8EKQ",
        "outputId": "07913969-70a8-43ed-920f-403825e6bbdd"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "positive\n",
            "0.51905286\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Expanded training data\n",
        "texts = [\n",
        "    \"I love programming\",             # Positive\n",
        "    \"Python is awesome\",              # Positive\n",
        "    \"I hate bugs\",                    # Negative\n",
        "    \"Debugging is fun\",               # Positive\n",
        "    \"I love solving problems\",        # Positive\n",
        "    \"I don't like errors\",            # Negative\n",
        "    \"Coding is exciting\",             # Positive\n",
        "    \"I hate when the code breaks\",    # Negative\n",
        "    \"Software development is amazing\", # Positive\n",
        "    \"I enjoy learning new languages\", # Positive\n",
        "    \"Fixing bugs is so satisfying\",   # Positive\n",
        "    \"I don't understand this error\",  # Negative\n",
        "    \"I love refactoring code\",        # Positive\n",
        "    \"Writing clean code feels great\", # Positive\n",
        "    \"I can't stand slow computers\",   # Negative\n",
        "    \"I'm frustrated with this bug\",   # Negative\n",
        "    \"I hate syntax errors\",           # Negative\n",
        "    \"I love the challenge of algorithms\", # Positive\n",
        "    \"Programming is a fun skill\",     # Positive\n",
        "    \"I am so happy my code works\",    # Positive\n",
        "    \"I don't like messy code\",        # Negative\n",
        "    \"Refactoring makes my code better\", # Positive\n",
        "    \"The debugger is my friend\",      # Positive\n",
        "    \"I can't figure out this logic\",  # Negative\n",
        "    \"This app is crashing\",           # Negative\n",
        "    \"Why won't my code compile?\",     # Negative\n",
        "    \"I love building projects\",       # Positive\n",
        "    \"I hate debugging this issue\",    # Negative\n",
        "    \"Coding is a lot of fun\",         # Positive\n",
        "    \"I dislike bad error messages\",   # Negative\n",
        "    \"Testing is an important part of development\", # Positive\n",
        "    \"I don't like working on legacy code\"  # Negative\n",
        "]\n",
        "\n",
        "labels = [\n",
        "    1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1,1,0\n",
        "]  # 1 = Positive, 0 = Negative\n"
      ],
      "metadata": {
        "id": "S5PA0mpW-oKn"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(texts)"
      ],
      "metadata": {
        "id": "NRo9V6K3_i9n"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequences= tokenizer.texts_to_sequences(texts)\n",
        "max_length = max([len(sequence) for sequence in sequences])"
      ],
      "metadata": {
        "id": "I8imnV9T_6Ts"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "X = pad_sequences(sequences, maxlen=max_length, padding='post')\n",
        "y = np.array(labels)\n",
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JTbyeZkwAV-A",
        "outputId": "e4cce00e-2d97-4902-b79c-886eac61be84"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1,  4, 13,  0,  0,  0,  0],\n",
              "       [24,  2, 25,  0,  0,  0,  0],\n",
              "       [ 1,  6, 14,  0,  0,  0,  0],\n",
              "       [15,  2,  9,  0,  0,  0,  0],\n",
              "       [ 1,  4, 26, 27,  0,  0,  0],\n",
              "       [ 1,  7, 10, 16,  0,  0,  0],\n",
              "       [17,  2, 28,  0,  0,  0,  0],\n",
              "       [ 1,  6, 29, 11,  3, 30,  0],\n",
              "       [31, 18,  2, 32,  0,  0,  0],\n",
              "       [ 1, 33, 34, 35, 36,  0,  0],\n",
              "       [37, 14,  2, 19, 38,  0,  0],\n",
              "       [ 1,  7, 39,  5, 20,  0,  0],\n",
              "       [ 1,  4, 21,  3,  0,  0,  0],\n",
              "       [40, 41,  3, 42, 43,  0,  0],\n",
              "       [ 1, 22, 44, 45, 46,  0,  0],\n",
              "       [47, 48, 49,  5, 50,  0,  0],\n",
              "       [ 1,  6, 51, 16,  0,  0,  0],\n",
              "       [ 1,  4, 11, 52, 12, 53,  0],\n",
              "       [13,  2, 23,  9, 54,  0,  0],\n",
              "       [ 1, 55, 19, 56,  8,  3, 57],\n",
              "       [ 1,  7, 10, 58,  3,  0,  0],\n",
              "       [21, 59,  8,  3, 60,  0,  0],\n",
              "       [11, 61,  2,  8, 62,  0,  0],\n",
              "       [ 1, 22, 63, 64,  5, 65,  0],\n",
              "       [ 5, 66,  2, 67,  0,  0,  0],\n",
              "       [68, 69,  8,  3, 70,  0,  0],\n",
              "       [ 1,  4, 71, 72,  0,  0,  0],\n",
              "       [ 1,  6, 15,  5, 73,  0,  0],\n",
              "       [17,  2, 23, 74, 12,  9,  0],\n",
              "       [ 1, 75, 76, 20, 77,  0,  0],\n",
              "       [78,  2, 79, 80, 81, 12, 18],\n",
              "       [ 1,  7, 10, 82, 83, 84,  3]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model=Sequential()\n",
        "model.add(Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=8, input_length=max_length))\n",
        "#model.add(Dropout(0.5))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(10, activation='relu'))\n",
        "model.add(Dense(5, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))"
      ],
      "metadata": {
        "id": "iVG_eDRRAbuZ"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "QyLIYctZAtb6"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X, y, epochs=50, batch_size=30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-rPL2JImAtda",
        "outputId": "121f264e-4c37-4fde-c1d8-803e13e28dab"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.5319 - loss: 0.6874\n",
            "Epoch 2/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5639 - loss: 0.6829\n",
            "Epoch 3/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5639 - loss: 0.6789\n",
            "Epoch 4/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5958 - loss: 0.6751\n",
            "Epoch 5/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5750 - loss: 0.6712\n",
            "Epoch 6/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5528 - loss: 0.6697\n",
            "Epoch 7/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5639 - loss: 0.6661\n",
            "Epoch 8/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5639 - loss: 0.6634\n",
            "Epoch 9/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5639 - loss: 0.6608\n",
            "Epoch 10/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5847 - loss: 0.6589\n",
            "Epoch 11/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5958 - loss: 0.6550\n",
            "Epoch 12/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5847 - loss: 0.6532\n",
            "Epoch 13/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5958 - loss: 0.6486\n",
            "Epoch 14/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6069 - loss: 0.6438\n",
            "Epoch 15/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5958 - loss: 0.6418\n",
            "Epoch 16/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5958 - loss: 0.6381\n",
            "Epoch 17/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5847 - loss: 0.6367\n",
            "Epoch 18/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6069 - loss: 0.6301\n",
            "Epoch 19/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5958 - loss: 0.6279\n",
            "Epoch 20/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5958 - loss: 0.6242\n",
            "Epoch 21/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5958 - loss: 0.6205\n",
            "Epoch 22/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5847 - loss: 0.6187\n",
            "Epoch 23/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5958 - loss: 0.6109\n",
            "Epoch 24/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6069 - loss: 0.6061\n",
            "Epoch 25/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5847 - loss: 0.6071\n",
            "Epoch 26/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5958 - loss: 0.5988\n",
            "Epoch 27/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.5847 - loss: 0.5983\n",
            "Epoch 28/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6278 - loss: 0.5923\n",
            "Epoch 29/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6278 - loss: 0.5876\n",
            "Epoch 30/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6278 - loss: 0.5811\n",
            "Epoch 31/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6167 - loss: 0.5813\n",
            "Epoch 32/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.6278 - loss: 0.5743\n",
            "Epoch 33/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6278 - loss: 0.5697\n",
            "Epoch 34/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6278 - loss: 0.5648\n",
            "Epoch 35/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6167 - loss: 0.5634\n",
            "Epoch 36/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6167 - loss: 0.5577\n",
            "Epoch 37/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6278 - loss: 0.5479\n",
            "Epoch 38/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6278 - loss: 0.5427 \n",
            "Epoch 39/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.6486 - loss: 0.5415 \n",
            "Epoch 40/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6486 - loss: 0.5368\n",
            "Epoch 41/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.6486 - loss: 0.5303\n",
            "Epoch 42/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6167 - loss: 0.5206 \n",
            "Epoch 43/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6167 - loss: 0.5193 \n",
            "Epoch 44/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.6278 - loss: 0.5088 \n",
            "Epoch 45/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6278 - loss: 0.5034\n",
            "Epoch 46/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6278 - loss: 0.4972 \n",
            "Epoch 47/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6167 - loss: 0.4922 \n",
            "Epoch 48/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6486 - loss: 0.4903\n",
            "Epoch 49/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.6486 - loss: 0.4843\n",
            "Epoch 50/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6486 - loss: 0.4697\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x780aad5fc9d0>"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_text = \"coding is not interested\"\n",
        "sample_sequence = tokenizer.texts_to_sequences([sample_text])  # Tokenize the sample text\n",
        "sample_padded = pad_sequences(sample_sequence, maxlen=max_length, padding='post')  # Pad the sequence\n",
        "prediction = model.predict(sample_padded)\n",
        "if prediction > 0.5:\n",
        "  print('positive')\n",
        "else:\n",
        "  print('negative')\n",
        "\n",
        "\n",
        "print(prediction[0][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fszkr4ENAySS",
        "outputId": "d70600ad-3045-48af-c18f-e47a92ac0da8"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "positive\n",
            "0.7344286\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Dense, Flatten, Dropout\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Expanded training data\n",
        "texts = [\n",
        "    \"I love programming\",             # Positive\n",
        "    \"Python is awesome\",              # Positive\n",
        "    \"I hate bugs\",                    # Negative\n",
        "    \"Debugging is fun\",               # Positive\n",
        "    \"I love solving problems\",        # Positive\n",
        "    \"I don't like errors\",            # Negative\n",
        "    \"Coding is exciting\",             # Positive\n",
        "    \"I hate when the code breaks\",    # Negative\n",
        "    \"Software development is amazing\", # Positive\n",
        "    \"I enjoy learning new languages\", # Positive\n",
        "    \"Fixing bugs is so satisfying\",   # Positive\n",
        "    \"I don't understand this error\",  # Negative\n",
        "    \"I love refactoring code\",        # Positive\n",
        "    \"Writing clean code feels great\", # Positive\n",
        "    \"I can't stand slow computers\",   # Negative\n",
        "    \"I'm frustrated with this bug\",   # Negative\n",
        "    \"I hate syntax errors\",           # Negative\n",
        "    \"I love the challenge of algorithms\", # Positive\n",
        "    \"Programming is a fun skill\",     # Positive\n",
        "    \"I am so happy my code works\",    # Positive\n",
        "    \"I don't like messy code\",        # Negative\n",
        "    \"Refactoring makes my code better\", # Positive\n",
        "    \"The debugger is my friend\",      # Positive\n",
        "    \"I can't figure out this logic\",  # Negative\n",
        "    \"This app is crashing\",           # Negative\n",
        "    \"Why won't my code compile?\",     # Negative\n",
        "    \"I love building projects\",       # Positive\n",
        "    \"I hate debugging this issue\",    # Negative\n",
        "    \"Coding is a lot of fun\",         # Positive\n",
        "    \"I dislike bad error messages\",   # Negative\n",
        "    \"Testing is an important part of development\", # Positive\n",
        "    \"I don't like working on legacy code\"  # Negative\n",
        "]\n",
        "\n",
        "labels = [\n",
        "    1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1,1,0\n",
        "]  # 1 = Positive, 0 = Negative\n",
        "\n",
        "# Step 2: Preprocess the Data\n",
        "tokenizer = Tokenizer(oov_token=\"<OOV>\")  # Handle out-of-vocabulary words\n",
        "tokenizer.fit_on_texts(texts)\n",
        "sequences = tokenizer.texts_to_sequences(texts)\n",
        "\n",
        "# Determine the maximum length of a sequence\n",
        "max_length = max([len(sequence) for sequence in sequences])\n",
        "\n",
        "# Pad the sequences to ensure they all have the same length\n",
        "X = pad_sequences(sequences, maxlen=max_length, padding='post')\n",
        "\n",
        "# Ensure the labels array has the same number of samples as X\n",
        "y = np.array(labels)\n",
        "\n",
        "# Step 3: Build the Model\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=8, input_length=max_length))\n",
        "model.add(Dropout(0.5))  # Add dropout to reduce overfitting\n",
        "model.add(Flatten())\n",
        "model.add(Dense(10, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))  # Binary classification\n",
        "\n",
        "# Compile the Model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Step 4: Train the Model\n",
        "model.fit(X, y, epochs=10, batch_size=2)\n",
        "\n",
        "# Step 5: Evaluate the Model\n",
        "loss, accuracy = model.evaluate(X, y)\n",
        "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
        "\n",
        "# Step 6: Check for OOV words in a new input\n",
        "sample_text = \"understading program is very tuff\"\n",
        "sample_sequence = tokenizer.texts_to_sequences([sample_text])\n",
        "\n",
        "# Check if the sequence has OOV tokens\n",
        "print(\"Tokenized sequence with possible OOV words:\", sample_sequence)\n",
        "\n",
        "# Count OOV words in the sample\n",
        "oov_count = sum(1 for word_id in sample_sequence[0] if word_id == tokenizer.word_index['<OOV>'])\n",
        "if oov_count > 0:\n",
        "    print(f\"Warning: The sample contains {oov_count} OOV words.\")\n",
        "else:\n",
        "    print(\"The sample contains no OOV words.\")\n",
        "\n",
        "#sample_text = \"not interesed coding\"\n",
        "#sample_sequence = tokenizer.texts_to_sequences([sample_text])  # Tokenize the sample text\n",
        "#sample_padded = pad_sequences(sample_sequence, maxlen=max_length, padding='post')  # Pad the sequence\n",
        "prediction = model.predict(sample_padded)\n",
        "if prediction > 0.5:\n",
        "  print('positive')\n",
        "else:\n",
        "  print('negative')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "abq5ju04BvGQ",
        "outputId": "8be5961e-2877-4ae6-991d-26a5ed013178"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6022 - loss: 0.6927\n",
            "Epoch 2/10\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4900 - loss: 0.6893     \n",
            "Epoch 3/10\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7364 - loss: 0.6799 \n",
            "Epoch 4/10\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6969 - loss: 0.6768 \n",
            "Epoch 5/10\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6733 - loss: 0.6736     \n",
            "Epoch 6/10\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8219 - loss: 0.6538 \n",
            "Epoch 7/10\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7886 - loss: 0.6637 \n",
            "Epoch 8/10\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8778 - loss: 0.6423 \n",
            "Epoch 9/10\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8676 - loss: 0.6310 \n",
            "Epoch 10/10\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9108 - loss: 0.6224 \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step - accuracy: 0.9375 - loss: 0.5890\n",
            "Accuracy: 93.75%\n",
            "Tokenized sequence with possible OOV words: [[1, 1, 3, 1, 1]]\n",
            "Warning: The sample contains 4 OOV words.\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step\n",
            "positive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Expanded training data\n",
        "texts = [\n",
        "    \"I love programming\",\n",
        "    \"Python is awesome\",\n",
        "    \"I hate bugs\",\n",
        "    \"Debugging is fun\",\n",
        "    \"I love solving problems\",\n",
        "    \"I don't like errors\",\n",
        "    \"Coding is exciting\",\n",
        "    \"I hate when the code breaks\",\n",
        "    \"Software development is amazing\",\n",
        "    \"I enjoy learning new languages\",\n",
        "    \"Fixing bugs is so satisfying\",\n",
        "    \"I don't understand this error\",\n",
        "    \"I love refactoring code\",\n",
        "    \"Writing clean code feels great\",\n",
        "    \"I can't stand slow computers\",\n",
        "    \"I'm frustrated with this bug\",\n",
        "    \"I hate syntax errors\",\n",
        "    \"I love the challenge of algorithms\",\n",
        "    \"Programming is a fun skill\",\n",
        "    \"I am so happy my code works\",\n",
        "    \"I don't like messy code\",\n",
        "    \"Refactoring makes my code better\",\n",
        "    \"The debugger is my friend\",\n",
        "    \"I can't figure out this logic\",\n",
        "    \"This app is crashing\",\n",
        "    \"Why won't my code compile?\",\n",
        "    \"I love building projects\",\n",
        "    \"I hate debugging this issue\",\n",
        "    \"Coding is a lot of fun\",\n",
        "    \"I dislike bad error messages\",\n",
        "    \"Testing is an important part of development\",\n",
        "    \"I don't like working on legacy code\"\n",
        "]\n",
        "\n",
        "labels = [\n",
        "    1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1,1,0\n",
        "]  # 1 = Positive, 0 = Negative\n",
        "\n",
        "# Step 2: Preprocess the Data\n",
        "tokenizer = Tokenizer(oov_token=\"<OOV>\")  # Handle out-of-vocabulary words\n",
        "tokenizer.fit_on_texts(texts)\n",
        "sequences = tokenizer.texts_to_sequences(texts)\n",
        "\n",
        "# Determine the maximum length of a sequence\n",
        "max_length = max([len(sequence) for sequence in sequences])\n",
        "\n",
        "# Pad the sequences to ensure they all have the same length\n",
        "X = pad_sequences(sequences, maxlen=max_length, padding='post')\n",
        "\n",
        "# Ensure the labels array has the same number of samples as X\n",
        "y = np.array(labels)\n",
        "\n",
        "# Step 3: Build the Model with LSTM\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=len(tokenizer.word_index) + 1,\n",
        "                    output_dim=8,\n",
        "                    input_length=max_length))\n",
        "model.add(LSTM(64, return_sequences=False))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(10, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Step 4: Train the Model\n",
        "model.fit(X, y, epochs=10, batch_size=2)\n",
        "\n",
        "# Step 5: Evaluate the Model\n",
        "loss, accuracy = model.evaluate(X, y)\n",
        "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
        "\n",
        "# Step 6: Make Predictions on New Data\n",
        "sample_text = \"I love programming but sometimes I face errors\"\n",
        "sample_sequence = tokenizer.texts_to_sequences([sample_text])\n",
        "sample_padded = pad_sequences(sample_sequence, maxlen=max_length, padding='post')\n",
        "prediction = model.predict(sample_padded)\n",
        "predicted_label = (prediction > 0.5).astype(\"int32\")\n",
        "print(f\"Prediction (1 = Positive, 0 = Negative): {predicted_label[0][0]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NRk6NiSuCef9",
        "outputId": "f10edcac-38c3-4d9c-b0d8-2e45d26dd2f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.7239 - loss: 0.6915\n",
            "Epoch 2/10\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6660 - loss: 0.6865\n",
            "Epoch 3/10\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6031 - loss: 0.6871\n",
            "Epoch 4/10\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4574 - loss: 0.6950\n",
            "Epoch 5/10\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5048 - loss: 0.6881\n",
            "Epoch 6/10\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5300 - loss: 0.6741\n",
            "Epoch 7/10\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5300 - loss: 0.6627\n",
            "Epoch 8/10\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5524 - loss: 0.5769\n",
            "Epoch 9/10\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8887 - loss: 0.2942\n",
            "Epoch 10/10\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.2531\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 353ms/step - accuracy: 1.0000 - loss: 0.1034\n",
            "Accuracy: 100.00%\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 232ms/step\n",
            "Prediction (1 = Positive, 0 = Negative): 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_text = \"not interesed coding\"\n",
        "sample_sequence = tokenizer.texts_to_sequences([sample_text])  # Tokenize the sample text\n",
        "sample_padded = pad_sequences(sample_sequence, maxlen=max_length, padding='post')  # Pad the sequence\n",
        "prediction = model.predict(sample_padded)\n",
        "if prediction > 0.5:\n",
        "  print('positive')\n",
        "else:\n",
        "  print('negative')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g_pFO-uND2ke",
        "outputId": "2bac88b7-9241-4b21-f7ea-fa53fc00836c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step\n",
            "positive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# 50 positive (label = 1), 50 negative (label = 0)\n",
        "labels = np.array([1]*50 + [0]*50)\n",
        "\n",
        "print(labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x7Uj3oLxbjP-",
        "outputId": "e0f7fd17-31c3-425e-f1e8-3ba950ac865f"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hIEJPXtnEE1S"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}